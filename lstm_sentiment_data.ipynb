{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maym5/lstm_vs_transformer/blob/main/lstm_vs__transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Evaluation Metrics:\n",
        "\n",
        "For prediction performance: Mean Absolute Percentage Error (MAPE).\n",
        "Specific implementation here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html\n",
        "\n",
        "### Import Statements"
      ],
      "metadata": {
        "id": "we5DLPU7RRw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras import layers\n",
        "import time\n",
        "import timeit"
      ],
      "metadata": {
        "id": "WR1qF1yHTzJZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Read Data"
      ],
      "metadata": {
        "id": "mq78VHvGTqmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amzn = pd.read_pickle(\"/Raw Data/pickle/amzn_prices_labels_news.pkl\")\n",
        "aapl = pd.read_pickle(\"/Raw Data/pickle/aapl_prices_labels_news.pkl\")\n",
        "msft = pd.read_pickle(\"/Raw Data/pickle/msft_prices_labels_news.pkl\")"
      ],
      "metadata": {
        "id": "N0zDlFShUC-2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['aapl', 'amzn', 'msft']"
      ],
      "metadata": {
        "id": "caHiSCpqAnVF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'neg', 'neu', 'pos', 'compound', 'subjectivity', 'polarity']\n",
        "y_col = ['Adj Close Next']"
      ],
      "metadata": {
        "id": "URjjhPIjihnf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_test_split(company):\n",
        "  if company == 'amzn':\n",
        "    X = amzn[X_cols]\n",
        "    y = amzn[y_col]\n",
        "  elif company == 'aapl':\n",
        "    X = aapl[X_cols]\n",
        "    y = aapl[y_col]\n",
        "  elif company == 'msft':\n",
        "    X = msft[X_cols]\n",
        "    y = msft[y_col]\n",
        "  split = int(0.8*X.shape[0])\n",
        "  X_train = X[:split]\n",
        "  X_test = X[split:]\n",
        "  y_train = y[:split]\n",
        "  y_test = y[split:]\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "3OUh0z32Ar4O"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(train, test, timestep, num_features) -> np.array:\n",
        "        train_remainder = train.shape[0] % timestep\n",
        "        test_remainder = test.shape[0] % timestep\n",
        "        if train_remainder != 0 and test_remainder != 0:\n",
        "            train = train[train_remainder:]\n",
        "            test = test[test_remainder:]\n",
        "        elif train_remainder != 0:\n",
        "            train = train[train_remainder:]\n",
        "        elif test_remainder != 0:\n",
        "            test = test[test_remainder:]\n",
        "        return window_and_reshape(train, timestep, num_features), window_and_reshape(test, timestep, num_features)"
      ],
      "metadata": {
        "id": "cOjo41QGqRx7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_and_reshape(data, timestep, num_features) -> np.array:\n",
        "        \"\"\"\n",
        "        Reformats data into shape our model needs,\n",
        "        namely, [# samples, timestep, # feautures]\n",
        "        samples\n",
        "        \"\"\"\n",
        "        samples = int(data.shape[0] / timestep)\n",
        "        result = np.array(np.array_split(data, samples))\n",
        "        return result.reshape((samples, timestep, num_features))"
      ],
      "metadata": {
        "id": "4j2JEdyHq0Hl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(X_train, X_test, y_train, y_test, epochs=25, batch_size=32) -> tf.keras.Model:\n",
        "  \"\"\"\n",
        "  Builds, compiles, and fits our LSTM baseline model.\n",
        "  \"\"\"\n",
        "  n_timesteps, n_features, n_outputs = 5, 12, 5\n",
        "  callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dense(n_outputs))\n",
        "  print('compiling baseline model...')\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
        "  print('fitting model...')\n",
        "  start = time.time()\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1, callbacks=callbacks)\n",
        "  print(time.time() - start)\n",
        "  return model, history"
      ],
      "metadata": {
        "id": "jxml3doZUL2x"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for company in datasets:\n",
        "  print(\"Training and Evaluating \",company, \" data: \")\n",
        "  X_train, X_test, y_train, y_test = create_train_test_split(company)\n",
        "  X_train_transform, X_test_transform = transform(X_train, X_test, 5, 12)\n",
        "  y_train_transform, y_test_transform = transform(y_train, y_test, 5, 1)\n",
        "  baseline = build_lstm(X_train_transform, X_test_transform, y_train_transform, y_test_transform)\n",
        "  model = baseline[0]\n",
        "  history = baseline[1]\n",
        "  print(model.summary())\n",
        "  print(\"Model Results: \")\n",
        "  print(model.evaluate(X_test_transform, y_test_transform))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqzaE-6BqaUT",
        "outputId": "a5b6c9e3-11cc-4b7d-eb09-1f8d76078d80"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating  aapl  data: \n",
            "compiling baseline model...\n",
            "fitting model...\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - 2s 309ms/step - loss: 99855959588864.0000 - mae: 7619821.5000 - mape: 4838167.0000 - val_loss: 23357781180416.0000 - val_mae: 3501547.2500 - val_mape: 1910328.0000\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 44345495388160.0000 - mae: 4794349.0000 - mape: 3046333.5000 - val_loss: 11546132480000.0000 - val_mae: 2420101.2500 - val_mape: 1319708.2500\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 21170319523840.0000 - mae: 3282619.7500 - mape: 2086445.1250 - val_loss: 4942861959168.0000 - val_mae: 1666818.7500 - val_mape: 907233.5000\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 9314932621312.0000 - mae: 2186402.0000 - mape: 1386251.0000 - val_loss: 2310930694144.0000 - val_mae: 1163051.7500 - val_mape: 630299.1250\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 4146809274368.0000 - mae: 1566759.3750 - mape: 994817.4375 - val_loss: 1925903417344.0000 - val_mae: 1148852.0000 - val_mape: 624037.6875\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3802241957888.0000 - mae: 1460921.5000 - mape: 925687.4375 - val_loss: 2185091874816.0000 - val_mae: 1057903.1250 - val_mape: 577682.8125\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3777889566720.0000 - mae: 1390780.3750 - mape: 877515.2500 - val_loss: 1689088163840.0000 - val_mae: 958006.1875 - val_mape: 521063.4062\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3472777805824.0000 - mae: 1328839.7500 - mape: 837148.5625 - val_loss: 1930017767424.0000 - val_mae: 1047534.1875 - val_mape: 572635.0000\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2632287518720.0000 - mae: 1129831.6250 - mape: 710561.6875 - val_loss: 1395873546240.0000 - val_mae: 861218.1875 - val_mape: 469260.0000\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 2096751312896.0000 - mae: 1005351.2500 - mape: 634856.1250 - val_loss: 1180230221824.0000 - val_mae: 839345.1875 - val_mape: 459697.3125\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 2215308427264.0000 - mae: 1054339.7500 - mape: 671596.3125 - val_loss: 974647066624.0000 - val_mae: 775248.7500 - val_mape: 422845.5000\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2036665548800.0000 - mae: 1043205.8125 - mape: 663158.1250 - val_loss: 1005571801088.0000 - val_mae: 776400.8750 - val_mape: 423876.0938\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1979639398400.0000 - mae: 998462.7500 - mape: 634550.0625 - val_loss: 827185823744.0000 - val_mae: 704854.8125 - val_mape: 384897.6875\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1361682759680.0000 - mae: 871558.5000 - mape: 553286.1250 - val_loss: 726840967168.0000 - val_mae: 637052.2500 - val_mape: 347633.5938\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1164842893312.0000 - mae: 815713.8125 - mape: 517920.4688 - val_loss: 613746933760.0000 - val_mae: 572735.1875 - val_mape: 312727.4375\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1111884955648.0000 - mae: 798663.5000 - mape: 507338.0625 - val_loss: 531352715264.0000 - val_mae: 532543.8125 - val_mape: 290806.0000\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1021337862144.0000 - mae: 777583.9375 - mape: 494229.4375 - val_loss: 562900828160.0000 - val_mae: 562885.3750 - val_mape: 309352.6875\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 871579648000.0000 - mae: 716137.6250 - mape: 454286.3750 - val_loss: 406871539712.0000 - val_mae: 491911.2500 - val_mape: 271092.6250\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 644126539776.0000 - mae: 620100.4375 - mape: 394961.4688 - val_loss: 347036254208.0000 - val_mae: 461763.8125 - val_mape: 254645.0469\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 503016128512.0000 - mae: 565130.0000 - mape: 360029.8125 - val_loss: 273236049920.0000 - val_mae: 429852.8125 - val_mape: 236608.6719\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 471014047744.0000 - mae: 532410.3750 - mape: 339525.8125 - val_loss: 252266332160.0000 - val_mae: 396648.6562 - val_mape: 218160.9219\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 469691858944.0000 - mae: 521111.0625 - mape: 332613.0938 - val_loss: 199640825856.0000 - val_mae: 344874.8125 - val_mape: 188757.5938\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 463149039616.0000 - mae: 512739.6562 - mape: 327563.9688 - val_loss: 177766891520.0000 - val_mae: 334154.9062 - val_mape: 182664.2812\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 397114408960.0000 - mae: 476750.0000 - mape: 304469.0312 - val_loss: 158516314112.0000 - val_mae: 322097.4062 - val_mape: 175787.9219\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 341268135936.0000 - mae: 445165.5625 - mape: 283700.1562 - val_loss: 149423620096.0000 - val_mae: 311515.8125 - val_mape: 169814.7188\n",
            "4.116092205047607\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 200)               170400    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180705 (705.88 KB)\n",
            "Trainable params: 180705 (705.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model Results: \n",
            "1/1 [==============================] - 0s 25ms/step - loss: 149423620096.0000 - mae: 311515.8125 - mape: 169814.7188\n",
            "[149423620096.0, 311515.8125, 169814.71875]\n",
            "Training and Evaluating  amzn  data: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compiling baseline model...\n",
            "fitting model...\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - 2s 302ms/step - loss: 26880535166976.0000 - mae: 3885040.5000 - mape: 3132946.5000 - val_loss: 7157158248448.0000 - val_mae: 1981251.8750 - val_mape: 1610326.2500\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 8833703346176.0000 - mae: 2234407.0000 - mape: 1784570.1250 - val_loss: 2208752992256.0000 - val_mae: 1203596.6250 - val_mape: 984545.3750\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2784062865408.0000 - mae: 1266885.5000 - mape: 1011836.5625 - val_loss: 1762551922688.0000 - val_mae: 1013561.8750 - val_mape: 824476.6250\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1939290324992.0000 - mae: 1090399.1250 - mape: 881119.3125 - val_loss: 1703017185280.0000 - val_mae: 1004983.3125 - val_mape: 815718.0000\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2337452589056.0000 - mae: 1176376.5000 - mape: 949577.8750 - val_loss: 1321052012544.0000 - val_mae: 936293.3750 - val_mape: 749777.6250\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2086454296576.0000 - mae: 1093188.7500 - mape: 888006.0000 - val_loss: 1322544922624.0000 - val_mae: 926265.0000 - val_mape: 749489.6875\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1948436004864.0000 - mae: 1067192.1250 - mape: 851452.6250 - val_loss: 1232565698560.0000 - val_mae: 825765.8750 - val_mape: 665447.6250\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1917860708352.0000 - mae: 1001997.0625 - mape: 813547.0000 - val_loss: 886572974080.0000 - val_mae: 687371.2500 - val_mape: 558785.4375\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1574315884544.0000 - mae: 883102.3750 - mape: 714446.1250 - val_loss: 636922953728.0000 - val_mae: 594423.7500 - val_mape: 487721.1250\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 863656804352.0000 - mae: 672717.1250 - mape: 548480.9375 - val_loss: 391850754048.0000 - val_mae: 458943.8125 - val_mape: 374799.0000\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 503842570240.0000 - mae: 479743.9688 - mape: 393933.3750 - val_loss: 272284794880.0000 - val_mae: 343654.6250 - val_mape: 282983.5625\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 235501355008.0000 - mae: 354056.4688 - mape: 282756.0312 - val_loss: 221782310912.0000 - val_mae: 342031.1250 - val_mape: 279045.4375\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 266117398528.0000 - mae: 388317.6875 - mape: 304050.6562 - val_loss: 268234047488.0000 - val_mae: 350167.6875 - val_mape: 285433.1562\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 380989276160.0000 - mae: 415863.5000 - mape: 324599.9375 - val_loss: 314030227456.0000 - val_mae: 381031.8750 - val_mape: 312468.0000\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 449793425408.0000 - mae: 470990.8438 - mape: 373595.6250 - val_loss: 255210815488.0000 - val_mae: 381793.6250 - val_mape: 312678.0625\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 398796226560.0000 - mae: 459474.8125 - mape: 364629.4375 - val_loss: 201351135232.0000 - val_mae: 350246.1875 - val_mape: 286564.7812\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 311893327872.0000 - mae: 420311.0312 - mape: 334245.3750 - val_loss: 136866570240.0000 - val_mae: 287082.3125 - val_mape: 233566.0625\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 197425643520.0000 - mae: 334798.9375 - mape: 265694.7812 - val_loss: 95285329920.0000 - val_mae: 213983.6562 - val_mape: 172225.4219\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 134576586752.0000 - mae: 254199.0625 - mape: 204548.7344 - val_loss: 84611203072.0000 - val_mae: 202103.3125 - val_mape: 160748.7656\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 114574008320.0000 - mae: 246385.2656 - mape: 199398.6094 - val_loss: 94738882560.0000 - val_mae: 235734.4219 - val_mape: 187593.5625\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 118605651968.0000 - mae: 261749.5312 - mape: 212192.9375 - val_loss: 94086103040.0000 - val_mae: 244047.5000 - val_mape: 195311.5781\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 120623431680.0000 - mae: 263414.7500 - mape: 212777.9062 - val_loss: 94525308928.0000 - val_mae: 250416.3125 - val_mape: 200111.1562\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 114421547008.0000 - mae: 260639.1719 - mape: 209755.4688 - val_loss: 81498570752.0000 - val_mae: 234878.9062 - val_mape: 187739.0000\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 99664838656.0000 - mae: 241997.8906 - mape: 193610.8906 - val_loss: 64973549568.0000 - val_mae: 205060.8906 - val_mape: 163853.3438\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 80298229760.0000 - mae: 208198.8906 - mape: 166229.5156 - val_loss: 50713083904.0000 - val_mae: 178029.5312 - val_mape: 142994.3281\n",
            "4.51502799987793\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 200)               170400    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180705 (705.88 KB)\n",
            "Trainable params: 180705 (705.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model Results: \n",
            "1/1 [==============================] - 0s 45ms/step - loss: 50713083904.0000 - mae: 178029.5312 - mape: 142994.3281\n",
            "[50713083904.0, 178029.53125, 142994.328125]\n",
            "Training and Evaluating  msft  data: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compiling baseline model...\n",
            "fitting model...\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - 2s 288ms/step - loss: 3352867635200.0000 - mae: 1513592.0000 - mape: 551666.1250 - val_loss: 1339487944704.0000 - val_mae: 975756.1250 - val_mape: 305894.8750\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1301676163072.0000 - mae: 933435.9375 - mape: 339000.5312 - val_loss: 532757413888.0000 - val_mae: 589567.3125 - val_mape: 184019.5156\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 547250700288.0000 - mae: 592475.5000 - mape: 216635.4375 - val_loss: 224755171328.0000 - val_mae: 381381.7812 - val_mape: 118417.5469\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 299222564864.0000 - mae: 397534.1250 - mape: 145599.0625 - val_loss: 216264540160.0000 - val_mae: 351866.0000 - val_mape: 109852.2422\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 323066396672.0000 - mae: 423287.7812 - mape: 154791.9375 - val_loss: 398309556224.0000 - val_mae: 500781.8438 - val_mape: 156744.9062\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 403626295296.0000 - mae: 518316.9062 - mape: 189499.8906 - val_loss: 440322850816.0000 - val_mae: 525868.3750 - val_mape: 163760.0000\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 379766276096.0000 - mae: 505960.2188 - mape: 184712.7344 - val_loss: 389256511488.0000 - val_mae: 487951.6562 - val_mape: 151952.9688\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 298123362304.0000 - mae: 443792.3438 - mape: 161929.1562 - val_loss: 294853574656.0000 - val_mae: 417852.2812 - val_mape: 130420.1406\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 192227409920.0000 - mae: 360116.1250 - mape: 131657.8438 - val_loss: 204463095808.0000 - val_mae: 326471.4688 - val_mape: 101682.5703\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 120697733120.0000 - mae: 271506.8438 - mape: 99645.8984 - val_loss: 126772166656.0000 - val_mae: 230364.9688 - val_mape: 70966.6562\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 82188705792.0000 - mae: 201514.8125 - mape: 74374.4922 - val_loss: 81168982016.0000 - val_mae: 186102.5312 - val_mape: 56849.8086\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 57460117504.0000 - mae: 166481.2188 - mape: 61200.8438 - val_loss: 67572244480.0000 - val_mae: 172753.5000 - val_mape: 52873.3008\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 63529963520.0000 - mae: 171628.6719 - mape: 63256.7188 - val_loss: 94582571008.0000 - val_mae: 196180.1094 - val_mape: 60561.5117\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 77571915776.0000 - mae: 199514.9844 - mape: 73203.2266 - val_loss: 93969137664.0000 - val_mae: 205081.5625 - val_mape: 63577.4844\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 87852466176.0000 - mae: 217400.0469 - mape: 79695.4219 - val_loss: 93105315840.0000 - val_mae: 213120.0000 - val_mape: 66275.3359\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 81376215040.0000 - mae: 215387.3594 - mape: 78780.8125 - val_loss: 82863472640.0000 - val_mae: 200298.1719 - val_mape: 62211.8906\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 70923665408.0000 - mae: 199974.9844 - mape: 73154.8594 - val_loss: 69792145408.0000 - val_mae: 182928.9375 - val_mape: 56853.9648\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 54830911488.0000 - mae: 172210.2500 - mape: 62893.1367 - val_loss: 64911233024.0000 - val_mae: 163158.0000 - val_mape: 50388.6680\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 42587672576.0000 - mae: 148055.7969 - mape: 54128.7500 - val_loss: 55853010944.0000 - val_mae: 139911.7344 - val_mape: 42882.4258\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 32423991296.0000 - mae: 131714.3594 - mape: 48212.8711 - val_loss: 50554773504.0000 - val_mae: 132479.1094 - val_mape: 40400.6094\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 26888056832.0000 - mae: 122030.3203 - mape: 44782.4141 - val_loss: 46590525440.0000 - val_mae: 126565.9297 - val_mape: 38503.1406\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 23524399104.0000 - mae: 113041.1875 - mape: 41694.7617 - val_loss: 43094724608.0000 - val_mae: 126118.7188 - val_mape: 38335.2422\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 22089060352.0000 - mae: 106940.5391 - mape: 39620.3438 - val_loss: 42785308672.0000 - val_mae: 124195.8359 - val_mape: 37735.0625\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 21243176960.0000 - mae: 102774.5625 - mape: 38138.0586 - val_loss: 39823204352.0000 - val_mae: 118152.4219 - val_mape: 35818.8672\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 20907339776.0000 - mae: 101526.9453 - mape: 37665.9336 - val_loss: 35855015936.0000 - val_mae: 107231.8359 - val_mape: 32518.9648\n",
            "4.300808906555176\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 200)               170400    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180705 (705.88 KB)\n",
            "Trainable params: 180705 (705.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model Results: \n",
            "1/1 [==============================] - 0s 28ms/step - loss: 35855015936.0000 - mae: 107231.8359 - mape: 32518.9648\n",
            "[35855015936.0, 107231.8359375, 32518.96484375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(test, preds, df, image_path=None, title_suffix=None, xlabel='AAPL stock Price'):\n",
        "  \"\"\"\n",
        "  Plots training data in blue, actual values in red, and predictions in green,\n",
        "  over time.\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(20,6))\n",
        "  # x = df.Close[-498:].index\n",
        "  plot_test = test[1:]\n",
        "  plot_preds = preds[1:]\n",
        "  x = df[-(plot_test.shape[0]*plot_test.shape[1]):].index\n",
        "  plot_test = plot_test.reshape((plot_test.shape[0]*plot_test.shape[1], 1))\n",
        "  plot_preds = plot_preds.reshape((plot_test.shape[0]*plot_test.shape[1], 1))\n",
        "  ax.plot(x, plot_test, label='actual')\n",
        "  ax.plot(x, plot_preds, label='preds')\n",
        "  if title_suffix==None:\n",
        "    ax.set_title('Predictions vs. Actual')\n",
        "  else:\n",
        "    ax.set_title(f'Predictions vs. Actual, {title_suffix}')\n",
        "  ax.set_xlabel('Date')\n",
        "  ax.set_ylabel(xlabel)\n",
        "  ax.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "cUKhYosNwAfA"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wYqFkEgsvzlx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}